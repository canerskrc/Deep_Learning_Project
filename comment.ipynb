{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMTv1e/lBi+VAlaD0ugsO0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/canerskrc/Deep_Learning_Project/blob/main/comment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEgSvHpfO0hb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv(os.path.join('data', 'train.csv', 'train.csv'))\n",
        "\n",
        "# print(df.head())\n",
        "\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "X = df['comment_text']\n",
        "y = df[df.columns[2:]].values\n",
        "\n",
        "print(df.columns)\n",
        "\n",
        "MAX_FEATURES = 200000\n",
        "\n",
        "vectorizer = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=1800, output_mode='int')\n",
        "\n",
        "vectorizer.adapt(X.values)\n",
        "\n",
        "print(vectorizer(\"Hello world, life is great!\"))\n",
        "\n",
        "vectorizer.get_vocabulary()\n",
        "\n",
        "vectorizer_text = vectorizer(X.values)\n",
        "print(vectorizer_text)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorizer_text, y))\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) # helps bottleneck\n",
        "\n",
        "batch_X, batch_y = dataset.as_numpy_iterator().next()\n",
        "print(batch_X.shape)\n",
        "\n",
        "train = dataset.take(int(len(dataset)*.7))\n",
        "val = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\n",
        "test = dataset.skip(int(len(dataset)*.9)).skip(int(len(dataset)*.1))\n",
        "\n",
        "# Sequential Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, Embedding, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(MAX_FEATURES+1, 32))\n",
        "model.add(Bidirectional(LSTM(32, activation='tanh')))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(6, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam')\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(train, epochs=10, validation_data=val)\n",
        "print(history.history)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(8.5))\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.show()\n",
        "\n",
        "input_text = vectorizer('You freaking suck!')\n",
        "print(input_text)\n",
        "\n",
        "batch = test.as_numpy_iterator().next()\n",
        "batch_X, batch_y = test.as_numpy_iterator().next()\n",
        "(model.predict(batch_X) > 0.5).astype(int)\n",
        "\n",
        "res = model.predict(np.expand_dims(batch_X))\n",
        "res.flatten()\n",
        "\n",
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy\n",
        "\n",
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = CategoricalAccuracy()\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "    # Unpack the batch\n",
        "    X_true, y_true = batch\n",
        "    # Make predictions\n",
        "    yhat = model.predict(X_true)\n",
        "\n",
        "    # Flatten the predictions and true values\n",
        "    y_true = y_true.flatten()\n",
        "    yhat = yhat.flatten()\n",
        "\n",
        "    pre.update_state(y_true, yhat)\n",
        "    re.updates_state(y_true, yhat)\n",
        "    acc.update_state(y_true, yhat)"
      ]
    }
  ]
}